---
title: 'Data Transformation: Iteration 2'
author: "Carson Slater"
date: '2022-10-21'
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
	echo = TRUE,
	message = FALSE,
	warning = FALSE
)
```

```{r, include=FALSE}
# Loading packages
library(tidymodels)
library(stringr)
library(janitor)
library(glmnet)
library(lubridate)
library(knitr)
library(mosaic)
```
```{r, eval=FALSE}
# Insert pathname below to load any data
path <- "/Users/carson/Documents/Wheaton Senior Year/Fall 2022/Mentored Research/new_baskets_adhie.csv"

df <- read.csv(path)
```

# Data Transformation Steps for the `Prophet` Modeling Process
### Preparing the Data with Robust Code (For Awantunai Data)
```{r, eval=FALSE}
# Finding Percentage of the Missing Data for each column.
colMeans(is.na(df))*100
# There is a very small proportion of missing data in these data 

df <- df %>% mutate(id = as.factor(id), 
                        order_id = as.factor(order_id), 
                        merchant_id = as.factor(merchant_id), 
                        sku_id = as.factor(sku_id), 
                        top_cat_id = as.factor(top_cat_id), 
                        sub_cat_id = as.factor(sub_cat_id))

# Cleaning data so that R can read the time stamp
df$placed_at = substr(df$placed_at, 1, nchar(df$placed_at)-4)

# Changing the placed_by into a POSIXct variable type
df$placed_at = as.Date(df$placed_at)

# Finding NA's
df %>% filter(is.na(df$top_cat_id))

# Removing the 11 NA's
df <- df %>% filter(!is.na(df$top_cat_id))


# Creating more columns with more date-specific information
df <- df %>% mutate(year = format(df$placed_at, "%Y"),
                        month = format(df$placed_at, "%m"),
                        day = format(df$placed_at, "%d"),
                        hour = format(df$placed_at, "%H"),
                        minute = format(df$placed_at, "%M"),
                        second = format(df$placed_at, "%S"),
                        yday = yday(df$placed_at),
                        wday = wday(df$placed_at),
                        yweek = week(df$placed_at))

# Creating factor variables for dates and times
df <- df %>% mutate(year = as.factor(year),
                        month = as.factor(month),
                        day = as.factor(day),
                        hour = as.factor(hour),
                        minute = as.factor(minute),
                        second = as.factor(second),
                        yday = as.factor(yday),
                        wday = as.factor(wday),
                        yweek = as.factor(yweek))

# Looking for duplicates orders
dupes <- get_dupes(df, order_id, placed_at, merchant_id, sku_id)

# Removing the duplicate observations
df <- df %>% distinct(order_id, placed_at, merchant_id, sku_id, .keep_all = TRUE)
```

### Exploratory Data Analysis
From my first iteration I learned that there is no 'one size fits all' forecasting model. I want to see if I can create a data frame that will contain all of the summary statistics for each SKU in a data set, containing range, mean order volume, median order volume, etc. 

```{r, eval=FALSE}
# Creating a data frame with the summary statistics for each SKU
sku_cnt <- df %>% count(sku_id) %>% filter(n >= 20)
  
sum_stats <- df %>% filter(df$sku_id %in% sku_cnt$sku_id) %>% 
  mutate(n = count(sku_id)) %>% 
  group_by(sku_id) %>%
  summarize(tot_vol = sum(qty),
            avg_qty = mean(qty),
            variance = var(qty),
            quartile1 = quantile(qty, 0.25),
            quartile3 = quantile(qty, 0.75),
            med_qty = median(qty),
            min = min(qty), 
            max = max(qty),
            range = max - min) %>% 
  distinct %>% 
  arrange(desc(tot_vol))
```

Here I think I have computed some summary statistics for these data. I want to dive deeper into these data to see if there are any noteworthy finds for each SKU.

```{r, eval=FALSE}
# total volume
sum_stats %>% arrange(desc(tot_vol)) %>% head(15) %>% kable()

sku_cnt %>% arrange(desc(n)) %>% head(5) %>% kable()

sum_stats %>% filter(sku_id == 1488)
sum_stats %>% filter(sku_id == 859)
sum_stats %>% filter(sku_id == 1497)
sum_stats %>% filter(sku_id == 866)
sum_stats %>% filter(sku_id == 976)
# most of these high frequency SKU's have very low variability in order quantites

sum_stats %>% arrange(desc(med_qty), desc(variance))
```

I need to transform the data and aggregate by day each `sku_id` order volume. *As of 10-26-2022, I believe the code below is incorrect.*

```{r, eval=FALSE}
by_day <- df %>%
  mutate(placed_at = as.Date(placed_at)) %>% 
  group_by(placed_at, sku_id) %>% 
  mutate(qty = sum(qty)) %>% 
  unique()

by_day_stats <- by_day %>% 
  mutate(n = count(sku_id)) %>% 
  group_by(sku_id) %>%
  summarize(tot_vol = sum(qty),
            avg_qty = mean(qty),
            variance = var(qty),
            quartile1 = quantile(qty, 0.25),
            quartile3 = quantile(qty, 0.75),
            med_qty = median(qty),
            min = min(qty), 
            max = max(qty),
            range = max - min) %>% 
  distinct %>% 
  arrange(desc(tot_vol))
```

*(10/26/2022) Below is the correct code for aggregating quantity per day for each SKU.*

```{r}
by_day2 <- df %>% select(placed_at, 
                         sku_id,
                         qty) %>% 
  mutate(placed_at = as.Date(placed_at)) %>% 
  group_by(placed_at, sku_id) %>% 
  summarize(qty = sum(qty))

by_day_stats2 <- by_day2 %>% 
  mutate(n = count(sku_id)) %>% 
  group_by(sku_id) %>%
  summarize(tot_vol = sum(qty),
            avg_qty = mean(qty),
            variance = var(qty),
            quartile1 = quantile(qty, 0.25),
            quartile3 = quantile(qty, 0.75),
            med_qty = median(qty),
            min = min(qty), 
            max = max(qty),
            range = max - min) %>% 
  distinct %>% 
  arrange(desc(tot_vol))
```

```{r, eval=FALSE}
load("Data_Iteration2.Rdata")
```

#### HALF-BAKED IDEA
Detect out liars by computing the 90-10 interval. Any outside of that can be ignored.

*I need to revisit this idea and make modifications*

We want to refine the SKU's that are worth forecasting.

```{r}
# filtering SKU's by arbtrary statistical thresholds
good_skus <- by_day_stats2 %>% filter(variance > 0, 
                                     range > 20, 
                                     med_qty > 3)

skus_vec <- as.vector(good_skus$sku_id)

by_day_filter <- by_day2 %>% 
  group_by(sku_id) %>% 
  filter(sku_id %in% skus_vec)
```

```{r, eval=FALSE}
save.image("Data_Iteration2.Rdata")
```

### EDA

```{r, include=FALSE}
# For visualization purposes
library(RColorBrewer)
n <- 50
qual_col_pals = brewer.pal.info[brewer.pal.info$category == 'qual',]

col_vector = unlist(mapply(brewer.pal, qual_col_pals$maxcolors, 
                           rownames(qual_col_pals)))

# The color schema I am using
pie(rep(1,n), col=sample(col_vector, n))
```

#### Volume of Goods Sold Each Year Month
```{r}
df_filter1 %>% 
  filter(placed_at >= max(df_filter1$placed_at) - months(12)) %>% 
  ggplot(aes(x = month, y= qty, fill = top_cat_id)) +
  geom_col() + 
  ylim(0,150000) + 
  labs(title = "Total Volume of FMCG Units Sold Each Month",
       x = "Month",
       y = "Volume",
       fill = "Category of Good",
       caption = "** Categories are obfuscated for privacy concerns **") +
  theme_minimal() +
  theme(plot.caption.position = "plot",
        plot.caption = element_text(hjust = 0)) +
  scale_fill_manual(values = col_vector)
```

Taking a look at the plot, this is very peculiar for me, what happens if we filter `top_cat_id` 27?

```{r}
df_filter1 %>% filter(top_cat_id != 27) %>% 
  filter(placed_at >= max(df_filter1$placed_at) - months(12)) %>% 
  ggplot(aes(x = month, y= qty, fill = top_cat_id)) +
  geom_col() + 
  ylim(0,150000) + 
  labs(title = "Total Volume of FMCG Units Sold Each Month",
       x = "Month",
       y = "Volume",
       fill = "Category of Good",
       caption = "** Categories are obfuscated for privacy concerns **") +
  theme_minimal() +
  theme(plot.caption.position = "plot",
        plot.caption = element_text(hjust = 0)) +
  scale_fill_manual(values = col_vector)
```

### Checking the Viability of My Filtered Data
```{r}
# This code chunk is simply to see if my prior code worked!
test <- by_day2 %>% filter(sku_id == 1209)
```
