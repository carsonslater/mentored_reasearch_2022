---
title: "Model Comparison"
author: "Carson Slater"
date: '2022-10-26'
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
	echo = TRUE,
	message = FALSE,
	warning = FALSE
)
```

```{r, include=FALSE}
# Loading packages
library(tidymodels)
library(tinytex)
library(stringr)
library(janitor)
library(glmnet)
library(lubridate)
library(knitr)
library(mosaic)
library(prophet)
```

```{r, eval=TRUE}
# Make sure you have your working directory configured such that it can find these data.
load("Data_Iteration2.Rdata")
```

# The Big Idea for this .Rmd

In my project, I have a forecasting model workflow with `Prophet`. The goal of this `.Rmd` is to create benchmark models and see how much better we can get Prophet to perform.

# Prepping the Data for the Modeling Process
```{r}
split <- by_day_filter %>% 
  rename(ds = placed_at, y = qty) %>% 
  group_by(sku_id) %>% 
  group_split()
```

# Additionally We Will Scale the Data [0,1]

I found that SKU's #757 (`split[[253]]`), #983 (`split[[293]]`), #1487 (`split[[356]]`), have either 338 or 339 observations, so these SKU's will be good to compare the time series modeling process on.

# Visualization for SKU's

We want to get a glimpse of what we are looking at. Hence, we know that we need to visualize the data for each of these goods.

```{r}
# 757
by_day_filter %>% 
  filter(sku_id == 757) %>% 
  ggplot(aes(x = placed_at, y = qty)) +
  geom_point() +
  geom_smooth() +
  geom_line(color = "red", alpha = 0.2) +
  labs(x = "Date",
       y = "Volume Purchased") +
  theme_minimal()

# 983
by_day_filter %>% 
  filter(sku_id == 983) %>% 
  ggplot(aes(x = placed_at, y = qty)) +
  geom_point() +
  geom_smooth() +
  geom_line(color = "red", alpha = 0.2) +
  labs(x = "Date",
       y = "Volume Purchased") +
  theme_minimal()

# 1488
by_day_filter %>% 
  filter(sku_id == 1487) %>% 
  ggplot(aes(x = placed_at, y = qty)) +
  geom_point() +
  geom_smooth() +
  geom_line(color = "red", alpha = 0.2) +
  labs(x = "Date",
       y = "Volume Purchased") +
  theme_minimal()
```

`sku_id` 757 appears to be a good where most of the time, the total volume distributed per day is below 10. This means it might not be the most urgent good to forecase. The other two, `sku_id` 983 and 1487 appear to be more seasonal and unpredictable with trend changes.

# Building a Benchmark `Prophet` Model
```{r}
# This is going to be a model for SKU_id #983

# Preprocessing
df <-  split[[293]] 

# Creating an evaluation data frame
eval <- df %>% 
  filter(ds >= max(df$ds) - weeks(8)) %>% 
  complete(ds = seq.Date(min(ds), max(ds), by="day")) %>% 
  mutate(y = ifelse(is.na(y), 0, y))
  
eval <- eval %>% slice(1:(n() - 1))

orig_df <- df

df <- df %>% filter(ds < max(df$ds) - weeks(8))
```

```{r}
mod <- prophet(df, 
               yearly.seasonality = TRUE, 
               fit = FALSE, 
               interval.width = 0.8) %>% 
  add_country_holidays(country_name = 'ID')

fit <- fit.prophet(mod, df)

# 2 Months
future <- make_future_dataframe(fit, periods = 8*7)

# Make a forecast
fcst <- predict(fit, future)

##########################################################
# Since we cannot have negative predictive quantities, 
# I invert the upper confidence interval and set the 
# negative yhats to zero
##########################################################

fcst <- fcst %>% mutate(diff = yhat_upper - yhat)

fcst <- fcst %>%
  mutate(yhat_upper = ifelse(yhat_upper >= 0, yhat_upper, diff)) %>% 
  mutate(yhat = ifelse(yhat >= 0, yhat, 0), 
         yhat_lower = ifelse(yhat_lower >= 0, yhat_lower, 0))

prophet_plot_components(fit, fcst)

# Final plot of forecast
plot(fit, fcst) + 
  add_changepoints_to_plot(m = fit, cp_color = "orange") +
  labs(title = "Fitted Model and Forecast of an SKU",
       x = "Date",
       y = "Volume Purchased") +
  theme_minimal()
```

```{r}
# Model Evaluation
pred <- fcst %>% filter(ds >= max(orig_df$ds) - weeks(8)) %>%
  select(ds, yhat_lower, yhat, yhat_upper)

# Make a tibble of errors from the days
err_df <- tibble(pred$ds, eval$y, pred$yhat)

colnames(err_df) <- c("ds", "y", "yhat")

# creating a residual column
err_df <- err_df %>% mutate(resid = y - yhat)

# We need to filter zeros for the err_df so that we can find MAPE
# If the observed value is zero, MAPE is infinity.
err_df <- err_df %>% filter(y != 0)

#library(Metrics)

# Get RMSE
Metrics::rmse(err_df$y, err_df$yhat)

# RMSE = 11.8242

# Get SMAPE
Metrics::smape(err_df$y, err_df$yhat) # can be infinity if predicted values in denominator are close to 1

# SMAPE = .4353

# A MAPE function
mean(abs((err_df$y-err_df$yhat)/err_df$y))

# MAPE = .4366 - not super good.

err_df %>% 
  ggplot(aes(x = resid)) +
  geom_histogram(binwidth = 5, 
                 fill = "orange", 
                 color = "grey") +
  labs(title = "Residual Plot",
       x = "Residual Value",
       y = "Frequency") +
  theme_minimal()
```

### Attempting to Tune Parameters of `Prophet` Model

Please ignore the following code chunk.
```{r, eval =FALSE}
# Plotting the original time series
#install.packages("TSstudio")
library(TSstudio)
library(xts)

# Plotting time series in base R plotting
ts <- xts(df$y, df$ds)

ts.plot(ts)

# What we are trying to predict (with ggplot2):
df %>% ggplot(aes(x = ds, y = y)) +
  geom_line() +
  xlab("") +
  scale_x_date(date_labels = "%Y %b %d")
```

### Testing Fourier Order
### Yearly Seasonality

This code chunk was my experimentation.
```{r}
# This code chunk is simply to explore what different parameters in Prophet do.
# This is also going to be a model for sku_id 1488.

# This is not the actualy time series, but the yearly trend
test1 <- prophet(df, yearly.seasonality = 3)
prophet:::plot_yearly(test1)

test2 <- prophet(df, yearly.seasonality = 10)
prophet:::plot_yearly(test2)

test3 <- prophet(df, yearly.seasonality = 20)
prophet:::plot_yearly(test3)
```

### SECOND `Prophet` Model

In this I added changepoints into the model, so that it can know that the trend is switching. AS a result the model performed slightly better.

```{r}
# See plot for SKU #983 to see how I selected changepoints
mod2 <- prophet(growth = "linear",
                changepoints = c("2022-03-11", "2022-06-08"),
                yearly.seasonality = FALSE,
                daily.seasonality = FALSE,
                seasonality.prior.scale = 10,
                holiday.prior.scale = 10,
                changepoint.prior.scale = 10,
                mcmc.samples = 0,
                interval.width = 0.8,
                uncertainty.samples = 1000,
                fit = FALSE
                )

# Fitting the Model
fit2 <- fit.prophet(mod2, df)

# 2 Months
future <- make_future_dataframe(fit2, periods = 8*7)

# Make a forecast
fcst2 <- predict(fit2, future)

##########################################################
# Since we cannot have negative predictive quantities, 
# I invert the upper confidence interval and set the 
# negative yhats to zero
##########################################################

fcst2 <- fcst2 %>% mutate(diff = yhat_upper - yhat)

fcst2 <- fcst2 %>%
  mutate(yhat_upper = ifelse(yhat_upper >= 0, yhat_upper, diff)) %>% 
  mutate(yhat = ifelse(yhat >= 0, yhat, 0), 
         yhat_lower = ifelse(yhat_lower >= 0, yhat_lower, 0))

prophet_plot_components(fit2, fcst2)

# Final plot of forecast
plot(fit2, fcst2) + 
  add_changepoints_to_plot(m = fit, cp_color = "orange") +
  labs(title = "Fitted Model and Forecast of an SKU",
       x = "Date",
       y = "Volume Purchased") +
  theme_minimal()
```

```{r}
# Model Evaluation
pred2 <- fcst2 %>% filter(ds >= max(orig_df$ds) - weeks(8)) %>%
  select(ds, yhat_lower, yhat, yhat_upper)

# Make a tibble of errors from the days
err_df2 <- tibble(pred2$ds, eval$y, pred2$yhat)

colnames(err_df2) <- c("ds", "y", "yhat")

# creating a residual column
err_df2 <- err_df2 %>% mutate(resid = y - yhat)

# We need to filter zeros for the err_df so that we can find MAPE
# If the observed value is zero, MAPE is infinity.
err_df2 <- err_df2 %>% filter(y != 0)

#library(Metrics)

# Get RMSE
Metrics::rmse(err_df2$y, err_df2$yhat)

# RMSE = 7.603284

# Get SMAPE
Metrics::smape(err_df2$y, err_df2$yhat) # can be infinity if predicted values in denominator are close to 1

# SMAPE = .2466916

# A MAPE function
mean(abs((err_df2$y-err_df2$yhat)/err_df2$y))

# MAPE = .340391

err_df2 %>% 
  ggplot(aes(x = resid)) +
  geom_histogram(binwidth = 3, 
                 fill = "orange", 
                 color = "grey") +
  labs(title = "Residual Plot",
       x = "Residual Value",
       y = "Frequency") +
  theme_minimal()
```

After reviewing the model evaluation metrics, this model was slightly better than the prior one. I need to keep tuning parameters to get the model to have the least amount of error.

In this I added changepoints into the model, so that it can know that the trend is switching. AS a result the model performed slightly better.

### THIRD `Prophet` Model
```{r}
mod3 <- prophet(growth = "linear",
                changepoints = c("2022-03-11", "2022-06-08"),
                yearly.seasonality = 2,
                daily.seasonality = FALSE,
                seasonality.prior.scale = 5,
                holiday.prior.scale = 5,
                changepoint.prior.scale = 1,
                mcmc.samples = 0,
                interval.width = 0.8,
                uncertainty.samples = 1000,
                fit = FALSE
                )
# Fitting the Model
fit3 <- fit.prophet(mod3, df)

# 2 Months
future <- make_future_dataframe(fit3, periods = 8*7)

# Make a forecast
fcst3 <- predict(fit3, future)

##########################################################
# Since we cannot have negative predictive quantities, 
# I invert the upper confidence interval and set the 
# negative yhats to zero
##########################################################

fcst3 <- fcst3 %>% mutate(diff = yhat_upper - yhat)

fcst3 <- fcst3 %>%
  mutate(yhat_upper = ifelse(yhat_upper >= 0, yhat_upper, diff)) %>% 
  mutate(yhat = ifelse(yhat >= 0, yhat, 0), 
         yhat_lower = ifelse(yhat_lower >= 0, yhat_lower, 0))

prophet_plot_components(fit3, fcst3)

# Final plot of forecast
plot(fit3, fcst3) + 
  add_changepoints_to_plot(m = fit, cp_color = "orange") +
  labs(title = "Fitted Model and Forecast of an SKU",
       x = "Date",
       y = "Volume Purchased") +
  theme_minimal()
```

```{r}
# Model Evaluation
pred3 <- fcst3 %>% filter(ds >= max(orig_df$ds) - weeks(8)) %>%
  select(ds, yhat_lower, yhat, yhat_upper)

# Make a tibble of errors from the days
err_df3 <- tibble(pred3$ds, eval$y, pred3$yhat)

colnames(err_df3) <- c("ds", "y", "yhat")

# creating a residual column
err_df3 <- err_df3 %>% mutate(resid = y - yhat)

# We need to filter zeros for the err_df so that we can find MAPE
# If the observed value is zero, MAPE is infinity.
err_df3 <- err_df3 %>% filter(y != 0)

#library(Metrics)

# Get RMSE
Metrics::rmse(err_df3$y, err_df3$yhat)

# RMSE = 7.603284

# Get SMAPE
Metrics::smape(err_df3$y, err_df3$yhat) # can be infinity if predicted values in denominator are close to 1

# SMAPE = .2466916

# A MAPE function
mean(abs((err_df3$y-err_df3$yhat)/err_df3$y))

# MAPE = .340391

err_df3 %>% 
  ggplot(aes(x = resid)) +
  geom_histogram(binwidth = 3, 
                 fill = "orange", 
                 color = "grey") +
  labs(title = "Residual Plot",
       x = "Residual Value",
       y = "Frequency") +
  theme_minimal()

```


### Writing a Function to Build a Model and Calculate Metrics
```{r, eval=FALSE}
# See plot for SKU #983 to see how I selected changepoints
mod2 <- prophet(growth = "linear",
                changepoints = c("2022-03-11", "2022-06-08"),
                yearly.seasonality = FALSE,
                daily.seasonality = FALSE,
                seasonality.prior.scale = 10,
                holiday.prior.scale = 10,
                changepoint.prior.scale = 10,
                mcmc.samples = 0,
                interval.width = 0.8,
                uncertainty.samples = 1000,
                fit = FALSE
                )
make_model <- function(mod, df) {
  # Creating an evaluation data frame
  eval <- df %>% 
    filter(ds >= max(df$ds) - weeks(8)) %>% 
    complete(ds = seq.Date(min(ds), max(ds), by="day")) %>% 
    mutate(y = ifelse(is.na(y), 0, y))
  
  eval <- eval %>% slice(1:(n() - 1))

  orig_df <- df

  df <- df %>% filter(ds < max(df$ds) - weeks(8))
  
  # Fitting the Model
  fit <- fit.prophet(mod, df)
  
  # 2 Months
  future <- make_future_dataframe(fit, periods = 8*7)
  
  # Make a forecast
  fcst <- predict(fit, future)
  
  fcst <- fcst %>% mutate(diff = yhat_upper - yhat)
  
  fcst <- fcst %>%
  mutate(yhat_upper = ifelse(yhat_upper >= 0, yhat_upper, diff)) %>% 
  mutate(yhat = ifelse(yhat >= 0, yhat, 0), 
         yhat_lower = ifelse(yhat_lower >= 0, yhat_lower, 0))
  
  prophet_plot_components(fit, fcst)
  
  # Final plot of forecast
  plot(fit2, fcst2) + 
  add_changepoints_to_plot(m = fit, cp_color = "orange") +
  labs(title = "Fitted Model and Forecast of an SKU",
       x = "Date",
       y = "Volume Purchased") +
  theme_minimal()
  
  # Model Evaluation
  pred <- fcst %>% filter(ds >= max(orig_df$ds) - weeks(8)) %>%
    select(ds, yhat_lower, yhat, yhat_upper)
  
  # Make a tibble of errors from the days
  err_df <- tibble(pred$ds, eval$y, pred$yhat)
  
  colnames(err_df) <- c("ds", "y", "yhat")
  
  # creating a residual column
  err_df <- err_df %>% mutate(resid = eval$y - yhat)
  
  # We need to filter zeros for the err_df so that we can find MAPE
  # If the observed value is zero, MAPE is infinity.
  err_df <- err_df %>% filter(y != 0)
  
  # Get RMSE
  print("RMSE:")
  print(Metrics::rmse(err_df$y, err_df$yhat))
  print("")
  
  # Get SMAPE
  print("SMAPE:")
  print(Metrics::smape(err_df$y, err_df$yhat))
  print("")
  
  # Get MAPE
  print("MAPE:")
  print(mean(abs((err_df$y-err_df$yhat)/err_df$y)))
  print("")
  
  err_df %>% 
  ggplot(aes(x = resid)) +
  geom_histogram(binwidth = 3, 
                 fill = "orange", 
                 color = "grey") +
  labs(title = "Residual Plot",
       x = "Residual Value",
       y = "Frequency") +
  theme_minimal()
}
```

### Testing Model-Building Function
```{r, eval=FALSE}
# This function does not work...
# There appears to be a problem with models that have more complex hyperparameters.
make_model(mod = mod2, df = df)
```

This function does not handle models with changepoints, and I am not sure why.

#Building Additional Models to Compare

In thinking a little bit about the modeling process and the mathematics behind the models I am considering, exponential smoothing might be the best alternative model. This is because the data is a "random walk" dataset.

```{r}
# Preprocessing
df <-  split[[293]] 

# Creating an evaluation data frame
eval <- df %>% 
  filter(ds >= max(df$ds) - weeks(8)) %>% 
  complete(ds = seq.Date(min(ds), max(ds), by="day")) %>% 
  mutate(y = ifelse(is.na(y), 0, y))
  
eval <- eval %>% slice(1:(n() - 1))

orig_df <- df

df <- df %>% filter(ds < max(df$ds) - weeks(8))
```

### Building Exponential Smoothig Models Using the `forecast` Package
```{r}
library(forecast)
library(lubridate)
library(zoo)
library(fpp2)
```

```{r}
# Finding the date-time conversions for the start day and week
startW <- as.numeric(strftime(head(df$ds, 1), format = "%W"))
startD <- as.numeric(strftime(head(df$ds, 1) + 1, format =" %w"))

# Checking to see if the time series will work with the date transformation
print(ts(data = df$y, frequency = 7, start = c(startW, startD)), calendar = T)
```

```{r}
# Making a time series object
y <- ts(data = df$y, frequency = 7, start = c(startW, startD))

autoplot(y) + ggtitle("Time Plot: Quantity of SKU per Week") + ylab("Total of SKU Sold")

# Stationary transform the data
y2 <- diff(y)

# Viewing the transformed data: change in real data over time
autoplot(y2)
```

```{r}
fit_ets <- ets(y, alpha = 0.2)

print(summary(fit_ets))

autoplot(fit_ets)

checkresiduals(fit_ets)
```

```{r}
fit_ets2 <- ets(y2)

print(summary(fit_ets2))

autoplot(fit_ets2)

checkresiduals(fit_ets2)
```


### Trying Again Using the `fpp2` Package

I think that I found a nice [article](https://www.geeksforgeeks.org/exponential-smoothing-in-r-programming/?utm_source=pocket_mylist) that explains how to do this with `tidymodels` and `fpp2`. So I am going ot give this a try with simple exponential smoothing (SES).

```{r}
# create training and testing set of the SKU data
startW.train <- as.numeric(strftime(head(df$ds, 1), format = "%W"))
startD.train <- as.numeric(strftime(head(df$ds, 1) + 1, format =" %w"))

startW.test <- as.numeric(strftime(head(eval$ds, 1), format = "%W"))
startD.test <- as.numeric(strftime(head(eval$ds, 1), format = "%W"))

# Create training and testing windows

# Training data (creates `ts` object)
sku.train <- ts(data = df$y, frequency = 7, start = c(startW.train, startD.train))

# Testing data
sku.test <- ts(data = eval$y, frequency = 7, start = c(startW.test, startD.test))
```

So apparently the `accuracy` function requires a `ts` object such that the `sku.train` and `sku.test` objects are indexed where the training data ends and the testing data begins, but I could not do that because I could not get the `stats::window` function to work. both are required, unless I want to hard code my own evaluation function into the code below. I can definitely try this, but it will be a tedious setback.

#### SES With the Trend
```{r}
# Making the SES model
ses.sku <- ses(sku.train,
                alpha = .2,
                h = 100)
autoplot(ses.sku) # this was with the trend
```

#### SES Without the Trend
```{r}
sku.dif <- diff(sku.train)
autoplot(sku.dif)
 
# reapplying SES on the filtered data
ses.sku.dif <- ses(sku.dif,
                    alpha = .2,
                    h = 100)
autoplot(ses.sku.dif)
```

#### Computing Evaluation Metrics
```{r, eval=FALSE}
# removing trend from test set
sku.dif.test <- diff(sku.test)
#accuracy(ses.sku.dif, sku.dif.test)

# comparing our model with other alphas
alpha <- seq(.01, .99, by = .01)
RMSE <- NA
for(i in seq_along(alpha)) {
  fit <- ses(sku.dif, alpha = alpha[i],
             h = 100)
  RMSE[i] <- accuracy(fit,
                      sku.dif.test)[2,2] # selecting RMSE from the object
}
 
# convert to a data frame and
# identify min alpha value
alpha.fit <- data_frame(alpha, RMSE)
alpha.min <- filter(alpha.fit,
                    RMSE == min(RMSE))
 
# plot RMSE vs. alpha
ggplot(alpha.fit, aes(alpha, RMSE)) +
  geom_line() +
  geom_point(data = alpha.min,
             aes(alpha, RMSE),
             size = 2, color = "red")
```

Well, all of the code above should work, but for the `accuracy` function, I cannot get the times series objects to line up with respect to indices.

### SES Using the `fable` Package
```{r}
library(fable)
```
```{r}
mdl_ses <- as_tsibble(orig_df) %>% 
  tsibble::fill_gaps(y = 0) %>% 
  model(ETS(y ~ error("A") + trend("N") + season("N")))

mdl_ses %>% report()

mdl_ses %>% components()
```

The code chunk below was strugling with the `map_dbl(y, ~pluck(.x, "sigma"))` function. I could not get it to return the standard deviation at each new time series increment.

```{r, eval=FALSE}
mdl_ses_fc <- mdl_ses %>%
  forecast(h = 5) %>%
  mutate(sigma = map_dbl(y, ~pluck(.x, "sigma")),
         ci_025 = qnorm(.025, .mean, sigma),
         ci_975 = qnorm(.975, .mean, sigma))

mdl_ses %>%
  augment() %>%
  ggplot(aes(x = ds)) +
  geom_line(aes(y = y)) +
  geom_line(aes(y = .fitted), color = "goldenrod") +
  geom_line(data = mdl_ses_fc, aes(y = .mean), color = "goldenrod") +
  geom_ribbon(data = mdl_ses_fc, 
              aes(ymin = ci_025, ymax = ci_975),
              alpha = 0.2, fill = "goldenrod") +
  theme_light() +
  labs(title = "Simple Exponential Smoothing ETS(A, N, N)",
       subtitle = "Algerian exports (% of GDP).")
```

The neat part is that I found code to run a comparative time series approach in [this bookdown](https://bookdown.org/mpfoley1973/time-series/exponential.html).

```{r}
library(tsibble)
orig_df %>%
  select(ds, y) %>% 
  as_tsibble() %>%
  tsibble::fill_gaps(y = mean(y)) %>% 
  stretch_tsibble(.init = 7, .step = 1) %>%
  model(
    OLS = TSLM(y ~ ds),
    `Simple Exponential Smoothing` = ETS(y ~ error("A") + trend("N") + season("N")),
    `Holt's method` = ETS(y ~ error("A") + trend("A") + season("N")),
    `Holt's method (damped)` = ETS(y ~ error("A") + trend("Ad") + season("N"))
  ) %>%
  forecast(h = 1) %>%
  accuracy(data = as_tsibble(orig_df)) # This was so cool!
```

**I need to make sure I cite the packages and also the bookdown on my poster.**

# What I Do Have to Show For

I have compiled metrics for one time series and can easily build two more on other SKU's.

#### A Prophet Model
```{r}
# for example

# Get RMSE
Metrics::rmse(err_df3$y, err_df3$yhat)

# RMSE = 7.140123

# Get SMAPE
Metrics::smape(err_df3$y, err_df3$yhat) # can be infinity if predicted values in denominator are close to 1

# SMAPE = 0.2509529

# A MAPE function
mean(abs((err_df3$y-err_df3$yhat)/err_df3$y))

# MAPE = 0.2800538

err_df3 %>% 
  ggplot(aes(x = resid)) +
  geom_histogram(binwidth = 1, 
                 fill = "orange", 
                 color = "grey") +
  labs(title = "Residual Plot",
       x = "Residual Value",
       y = "Frequency") +
  theme_minimal()

```

The residuals look normally distributed, which means that the model does not appear to be overfitting, nor does it appear to be leaving some information out.

#### An ETS model
```{r}
print(summary(fit_ets))

autoplot(fit_ets)

checkresiduals(fit_ets)
```

Again, the residuals look normally distributed, which means that the model does not appear to be overfitting, nor does it appear to be leaving some information out. The only issue is that the RMSE slightly larger.

#### Removing Outliers Idea
Remove outlier and impute? (Do not have time before project deadline.)

# Using a Different SKU
```{r}
# This is going to be a model for sku_id #1487

# Preprocessing
df <-  split[[356]] 
```

There are a couple outliers in this dataframe. So I took out the observations that were not within two standard deviations of the time series.

```{r}
#library(mosaic)
favstats(df$y) %>% kable()
df <- df %>% filter(near(y, mean(df$y), tol = 2*stats::sd(df$y)))
```

```{r}

# Creating an evaluation data frame
eval <- df %>% 
  filter(ds >= max(df$ds) - weeks(8)) %>% 
  complete(ds = seq.Date(min(ds), max(ds), by="day")) %>% 
  mutate(y = ifelse(is.na(y), 0, y))
  
eval <- eval %>% slice(1:(n() - 1))

orig_df <- df

df <- df %>% filter(ds < max(df$ds) - weeks(8))
```

#### Classifying the Time Series as White Noise
To classify a time series as white noise, three assumptions must be met.

```{r}
# 1488
by_day_filter %>% 
  filter(sku_id == 1487) %>% 
  ggplot(aes(x = placed_at, y = qty)) +
  #geom_point() +
  geom_smooth() +
  geom_line(color = "red", alpha = 0.8) +
  labs(x = "Date",
       y = "Volume Purchased") +
  theme_minimal()

orig_df.dif <- diff(orig_df$y)

mean(orig_df.dif) # Mean is close to zero, so we can assume this is white noise

# Take the first difference of the times series to get a white noise series
orig_df %>% 
  head(324) %>% 
  ggplot(aes(x = ds, y = orig_df.dif)) +
  geom_line(color = "red")

# We want to plot an autocorrelation plot to further check if this is a white noise time series

# Finding the date-time conversions for the start day and week
startW <- as.numeric(strftime(head(df$ds, 1), format = "%W"))
startD <- as.numeric(strftime(head(df$ds, 1) + 1, format =" %w"))

# Checking to see if the time series will work with the date transformation
print(ts(data = df$y, frequency = 7, start = c(startW, startD)), calendar = T)
```

```{r}
# Making a time series object
y <- ts(data = df$y, frequency = 7, start = c(startW, startD))

acf(y, lag.max = 10, plot = TRUE, type = "correlation")
```


From the plot it looks like the changepoints are at 04-09-2022 and 06-15-2022.

```{r}
# See plot for SKU #983 to see how I selected changepoints
mod4 <- prophet(growth = "linear",
                changepoints = c("2022-04-09", "2022-06-15"),
                yearly.seasonality = FALSE,
                daily.seasonality = FALSE,
                seasonality.prior.scale = 10,
                holiday.prior.scale = 10,
                changepoint.prior.scale = 0.4,
                mcmc.samples = 0,
                interval.width = 0.8,
                uncertainty.samples = 1000,
                fit = FALSE
                )

# Fitting the Model
fit4 <- fit.prophet(mod4, df)

# 2 Months
future <- make_future_dataframe(fit4, periods = 8*7)

# Make a forecast
fcst4 <- predict(fit4, future)

##########################################################
# Since we cannot have negative predictive quantities, 
# I invert the upper confidence interval and set the 
# negative yhats to zero
##########################################################

fcst4 <- fcst4 %>% mutate(diff = yhat_upper - yhat)

fcst4 <- fcst4 %>%
  mutate(yhat_upper = ifelse(yhat_upper >= 0, yhat_upper, diff)) %>% 
  mutate(yhat = ifelse(yhat >= 0, yhat, 0), 
         yhat_lower = ifelse(yhat_lower >= 0, yhat_lower, 0))

prophet_plot_components(fit4, fcst4)

# Final plot of forecast
plot(fit4, fcst4) + 
  add_changepoints_to_plot(m = fit4, cp_color = "orange") +
  labs(title = "Fitted Model and Forecast of an SKU",
       x = "Date",
       y = "Volume Purchased") +
  theme_minimal()
```

```{r}
# Model Evaluation
pred4 <- fcst4 %>% filter(ds >= max(orig_df$ds) - weeks(8)) %>%
  select(ds, yhat_lower, yhat, yhat_upper)

# Make a tibble of errors from the days
err_df4 <- tibble(pred4$ds, eval$y, pred4$yhat)

colnames(err_df4) <- c("ds", "y", "yhat")

# creating a residual column
err_df4 <- err_df4 %>% mutate(resid = y - yhat)

# We need to filter zeros for the err_df so that we can find MAPE
# If the observed value is zero, MAPE is infinity.
err_df4 <- err_df4 %>% filter(y != 0)

#library(Metrics)

# Get RMSE
Metrics::rmse(err_df4$y, err_df4$yhat)

# RMSE = 7.603284

# Get SMAPE
Metrics::smape(err_df4$y, err_df4$yhat) # can be infinity if predicted values in denominator are close to 1

# SMAPE = .2466916

# A MAPE function
mean(abs((err_df4$y-err_df4$yhat)/err_df4$y))

# MAPE = .340391

err_df4 %>% 
  ggplot(aes(x = resid)) +
  geom_histogram(binwidth = 5, 
                 fill = "orange", 
                 color = "grey") +
  labs(title = "Residual Plot",
       x = "Residual Value",
       y = "Frequency") +
  theme_minimal()
````
